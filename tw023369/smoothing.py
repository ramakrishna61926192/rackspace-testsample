'''
Smoothing module holds the python code to execute the smoothing process to generate a baseline

The module uses singledispatch to configure the processing for fthe baseline mode { config parmateter) 
and the demand process configuration (process_config parameter).The demand process configuation detrmines 
most of the variation in the code.

The entry point to the module is the create_smoothed_baseline function.  
This handles all the setup dependent upon the config variable.  It chooses which history stream will be smoothed and, 
in tha case of Holiday suppresses smoothing all together as we canuse results form earlier runs.


For efficiency reasons the actual smoothing algorithms are written in cython. Those cython routines execute on 
numpy arrays that are created from pandas dataframes in this module using the dfreshape function from the common module

dfreshape takes named columns from a dataframe and transforms them each into either 2 or 3 dimensional numpy array 
depending on parocess_config. If process_config  is DOW (Day_Of_Week)the array is 3 dimensional ( geog, observations, day) 
otherwise two
dimensions (geog, observations).  The cardinality of observations depends if the history is in week buckets or days.

The required dimensions are generated by the as_shape function

    
    >>> geog_count= 100
    >>> weeks = 20
    >>> dow= DOW()
    >>> week = Weeks()
    >>> days = Days()
    >>> as_shape(dow, geog_count, weeks) # seven timeseries per geog, each 20 observations long
    (100, 20, 7)                         
    >>> as_shape(days, geog_count, weeks) # one time series per geog, 140 observations long
    (100, 140)                           
    >>> as_shape(week, geog_count,weeks) # one time series per geog, one observation for each of 20 weeks
    (100, 20)                            

Smoothing is run on each of these tim series . The extra dimension on DOW is handled as special case 
where necessary
'''
import pandas as pd
import numpy as np


import pyximport
pyximport.install(setup_args={"include_dirs":np.get_include()},
                  reload_support=True)

# Optimized cython algorithms
from HAVI.JDA_demand.algos.smooth_item_array import smooth_a_history
from HAVI.JDA_demand.algos.ewma import ewma

from HAVI.JDA_demand.common import *
from HAVI.JDA_demand.constants import *
from HAVI.JDA_demand.configurations import *
from singledispatch import singledispatch
from HAVI.JDA_demand.baseline.validations import run_validations
from numba import  guvectorize, njit

import logging 
logging.getLogger(__name__)

def get_smoothing_models_for_geog(geog, params, isMain=None):
    ''' Pull the models that match this stage of the smoothing process.
    
    Return thenm as alist that will be passed to the cython algorithms in the correct sequence to match the 
    function parameters.
    '''
    models = params.get_model(geog)
    return [ models[k] for k in (P_MAIN_MODELS if isMain else P_OVERLAY_MODELS) ]

def get_smoothing_flags(config, geog, params, flag_sets):
    ''' This is a stub, always returns the same flag set.
    
    Any flag in th returned set will be considered a bad day for smoothing algorithms
    
    In the final version we may want to  have some logi to decide if zeros are good days.
    '''
    
    return flag_sets[P_SMOOTHING_ZEROS_BAD]

@singledispatch
def _run_smooth(process_config,
                       idx,
                       hist, 
                       bad_days,
                       smoothed_hist,
                       new_good,
                       window,
                       first_day, 
                       models,
                       bad_flag_set,
                       bread,
                       isMain=True):
    '''Alternate path with a 2D array if smoothing by day of week not requested
    
    This is one history stream for the dfu.  Closed days will be handled in the
    smoothing if the closed flag is set in bad_days
    
    this will also handle any item that is in weekly periods
    in this case start day of week and end_day of week will be 0.
    '''
    
    good_obs = np.array(noneSet(flags, bad_flag_set), 'uint16')
    from_period  = window.start_week + window.start_day 
    to_period = window.end_week + window.end_day 
                
    # The store is open this day of the week so we expect history 
    (smoothed_hist[idx,from_period:to_period],
         new_good[idx,from_period:to_period],
         return_status) =  smooth_a_history(hist[idx,from_period:to_period],
                                            good_obs[idx,from_period:to_period],
                                            process_config.verbosity,
                                            isMain,
                                            bread(),
                                            *models) 
     
    return np.array([return_status], dtype ='uint16')

@_run_smooth.register(DOW)
def _run_smooth_by_day(process_config,
                       idx,
                       hist, 
                       flags,
                       smoothed_hist,
                       new_good,
                       window,
                       first_day, 
                       models,
                       bad_flag_set,
                       bread,
                       isMain=True):
    
    ''' The inner loop logic to process by day of week ( 3D array)
    
    This returns a status code for each day of week per geog -- no clue yet what happens to this
    '''
    good_obs = np.array(noneSet(flags, bad_flag_set), 'uint16')
    return_status = np.zeros((7,), dtype= 'uint16')
    for j in range(7) :
        # add the day of week to the breadcrumb
        #Need to rotate array based on earliest_date weekday
        bread.push('Day',DAYNAMES[(j+ first_day) % 7] )
        
        # align the start and end of the timeseries
        # e,g.  If j is 3 and the start day of the window is day4 , 
        # day 3 in week 0 is not in the g=window for his geog.
        # Simillarly for end day but in reverse
        from_week = window.start_week + (1 if window.start_day > j else 0)
        to_week   = window.end_week -(1 if window.end_day < j else 0)
        (smoothed_hist[idx,from_week:to_week,j],
             new_good[idx,from_week:to_week,j],
             return_status[j]) =  smooth_a_history(hist[idx,from_week:to_week,j],
                                                    good_obs[idx,from_week:to_week,j], # convert bad_flags to good
                                                    process_config.verbosity,
                                                    bread(),
                                                    isMain,
                                                    *models) 
        bread.pop() 
    return return_status
    
@singledispatch   
def merge_overlay(process_config,
                  idx,
                  smoothed_hist,
                  overlay_smoothed_hist,
                  new_good,
                  overlay_new_good,
                  window,
                  return_status, 
                  overlay_status ):
    '''Merge the results of overlay calculation into the overall result.
    
    Overlay is only used if the return status is 
    ''' 
    if overlay_status[0] ==0 or return_status[0] !=0:
        from_period  = window.start_week + window.start_day_of_week 
        to_period = window.end_week + window.end_day_of_week 
        
        smoothed_hist[idx,from_period:to_period ]  = overlay_smoothed_hist[idx,from_period:to_period ]   
        new_good[idx,from_period:to_period ]  = overlay_new_good[idx,from_period:to_period ] 
        
    return overlay_status 
        
@merge_overlay.register(DOW)      
def merge_overlay_by_day(process_config,
                  idx,
                  smoothed_hist,
                  overlay_smoothed_hist,
                  new_good,
                  overlay_new_good,
                  window,
                  return_status, 
                  overlay_status ):
    
    for j in range(7):
        if overlay_status[j] ==0: # or return_status[j] !=0:  -- why did I think this was good idea
            from_week = window.start_week + (1 if window.start_day > j else 0)
            to_week   = window.end_week +(1 if window.end_day > j else 0)
            
            smoothed_hist[idx,from_week:to_week, j ]  = overlay_smoothed_hist[idx,from_week:to_week , j]   
            new_good[idx,from_week:to_week, j ]  = overlay_new_good[idx,from_week:to_week , j] 
            
        
    return return_status 
    

def run_smoothing(process_config,
                  config,
                  hist,
                  flags,
                  geog_sales, 
                  params,
                  weeks,
                  publish_weeks,
                  earliest_hist_date,
                  bread,
                  flag_sets = None,
                  geog_windows=None,
                  overlay_windows=None):
    ''' Generate a baseline from a history time series.
    
    hist and flags are two timeseries represent as 3 dimensional 
    numpy arrays.
    
    
    Depending on why this job is being run hist may be either the actual sales data 
    or  deseasonalized sales.
    
    goodx is 1/0 flag indicating whether the matching data in hist is considered 
    'good ' for smoothing. Depending on the algorithm applied days marked not good,
    goodx ==0, may be excluded from consideration in determining a baseline value.
    
    loc_count  == hist.shape[0]  integer the number of distinct store in the array
    high_low == 1 dim array holding the parameters used to  detrmine if thes tore is to be 
                processed as normal, low or very low
    smoothing_params = a dict with three keys normal, low, and very low.  Based on the 
                       determination of the store activity the value for each key 
                       returns the parameters that define the smoothing algorithm to be used.
    
    bread =  a Breadcrumb to label exceptions with the entity being processed
    
    verbosity = log level control in cython code 
    
    Code respects the start date and end dates of a dfu history and will only calculte and 
    publish values in that window
    
    Outputs
    smoothed_history = the generated baseline -- same shape and dtype as hist
    new_good         = the datapoints determined to be good after finding otliers in smoothing
                       -- the same shape and dtype as goodx
    return_status    = an integer return status for each (rest, dayofweek) to determine 
                       if any furtherprocessing is reqired
                       0 = normal return
                       1 = goodx is all zeros , no good days to use in smoothing
                       2 = Required smoothing, mapd_tol not obtained after max_cycles
                       3 = Smoothed_history contains NaNs
                       Shape (loc_count, 7)
                       
    '''
    # Create output arrays 
    smoothed_hist  = np.empty_like(hist)
    smoothed_hist[...] = np.nan
    new_good =  np.zeros_like(flags)
    

    if overlay_windows:
        overlay_smoothed_hist = np.empty_like(hist)
        overlay_smoothed_hist[...] = np.nan
        overlay_new_good = np.empty_like(flags)
        
     
    res = []
    # This value 0..6 will be used to align the array with parameters mbsed on
    # day of weeks assuming monday as the first day of the week.  Here the first day 
    # depends upon what the last date is usually determined by which day the job runs
    first_day  = earliest_hist_date.weekday()
    res =[]
    for idx, (geog, window) in enumerate(geog_windows.iteritems()):
        #Smooth history for ith store
        bread.push('Geog', str(geog))
        geog_class = geog_sales.loc[geog_sales.geog == geog,:].itertuples().next()
        models = get_smoothing_models_for_geog(geog_class, params, isMain=True)
        geog_params  = params.get_params(geog_class)
        
        bad_flag_set = get_smoothing_flags(config, geog_class, params, flag_sets)
        
        #Updates smoothed_hist and new Good as a side effect.
        return_status =_run_smooth(process_config,
                        idx,
                        hist, 
                        flags,
                        smoothed_hist, # output 
                        new_good, # output
                        window,
                        first_day, 
                        models,
                        bad_flag_set,
                        bread,
                        isMain=True
                       )
         
        # Run overlay smoothing if required for this geog
        if models[0][P_OVERLAY_SMOOTH] != M_NONE:
            for overlay in overlay_windows:
                # is this period in the window when the store was open
                # So set up the window we would overwite the main smoothing
                # Could extend this too not temp closed the whole period
                
                models = get_smoothing_models_for_geog(geog_class, params, isMain=False)
                overlay_start = max([overlay.publish_start_week, overlay.publish_start_day],
                                    [window.start_week, window.start_day])
                overlay_end   = min([overlay.publish_end_week, overlay.publish_end_day],
                                    [window.end_week, window.end_day])
                if overlay_start<= overlay_end:
                    #there is aat leat one day to overwrite
                    #we now need two window objects one foe the calculation
                    # and the other for where the ovelay value replace the main smooth values
                    overlay_window =  GeogWindow(*(overlay_start+overlay_end) )
                    overlay_calc_window = GeogWindow(*(max([overlay.start_week, overlay.start_day],
                                                         [window.start_week, window.start_day]) + 
                                                     min([overlay.publish_end_week, overlay.publish_end_day],
                                                         [window.end_week, window.end_day])) )
                    # note we are using the same flags we have not updated the flags with any volume outliers found 
                    # in main smoothing
                    overlay_status =_run_smooth(process_config,
                                  idx,
                                  hist, 
                                  flags,
                                  overlay_smoothed_hist, # output 
                                  overlay_new_good,  # output
                                  overlay_calc_window,
                                  first_day, 
                                  models,
                                  bad_flag_set,
                                  bread,
                                  isMain=False)
                    
                    # What do we do if overlay does not return a result and main method does
                    return_status = merge_overlay(process_config,
                                                          idx,
                                                          smoothed_hist,
                                                          overlay_smoothed_hist,
                                                          new_good, 
                                                          overlay_new_good, 
                                                          overlay_window, 
                                                          return_status, 
                                                          overlay_status )
            res.append(return_status)
            
        return_status = np.vstack(res)
        if not process_config.byDay:
            return_status = return_status.squeeze()
        
            #using np ufunc to apply agccross dimaensions
        old_good = np.array(noneSet(flags, bad_flag_set), 'uint16')
        # find all points where the good flag has been unset
        delta_bad = (old_good & ~ new_good)
        
        # if delta bad id zero keep the current setting, 
        # if delata_bad is 1 take the current valure and add the qty outlier setting
        new_flags = np.choose(delta_bad, [flags, set_flag(flags, P_OUTLIER)])
        
        
        return_status  = run_validations ( process_config,
                                           config,
                                           hist, 
                                           smoothed_hist,
                                          flags,
                                          new_good,
                                          return_status,
                                          flag_sets,
                                          params,
                                          geog_sales,
                                          bread)      
#         res.append(return_status)
#         bread.pop()
#     # generate a return_code array 
#     #The squeeze is required to confor the array shape if not DOW smoothing.                
#     return_status = np.vstack(res).squeeze()
#     
    
#   
    return smoothed_hist, new_flags, return_status


def smooth_all_geogs(config, 
                     process_config,
                     hist_df,
                     geogs,
                     geog_count,            
                     geog_windows,
                     overlay_windows,
                     params=None,
                     total_units=None,
                     preped_units=None,
                     result_units=None,
                     bad_day_flags='flags',
                     flag_sets =None,
                     bread=None ):
    
    '''
    '''
    
    weeks = config.hist_lookback                             
    # Modify the period count parameters to handle weekly buckets
    # ----------------------------DATAFRAME -> NDARRAYS
    (preped_ts,
        sales_ts,
        bad_day) = hist_df.pipe(dfreshape,
                                 [preped_units, 
                                  total_units, 
                                   
                                  bad_day_flags,], 
                                  as_shape(process_config,
                                                 geog_count,
                                                 weeks) )
    sales_ts  = np.array(sales_ts, dtype  = 'float32')   
    preped_ts = np.array(preped_ts, dtype  = 'float32')
    (baseline,
       new_flags,
       return_status) =run_smoothing(process_config,
                                  config,
                                  preped_ts,
                                  bad_day,
                                  geogs,
                                  params,
                                  weeks,
                                  config.publish_window,
                                  config.hist_start_date,
                                  bread,
                                  flag_sets = flag_sets,
                                  geog_windows = geog_windows,
                                  overlay_windows = overlay_windows)

    hist_count  = len(hist_df)
    # ----------------------- NDARRAYs ->-DATAFRAME
    hist_df[result_units] = baseline.reshape((hist_count,))
    hist_df[bad_day_flags] = new_flags.reshape((hist_count,))
    
    # this needs to be made shape agnostic
    return_status  = pd.DataFrame.from_records(return_status.reshape(len(geogs),7),
                                  index = geogs.geog, columns  =DAYNAMES)
    return hist_df, return_status



@singledispatch
def create_smoothed_baseline(config, hist_df, geogs, geog_count, geog_windows, overlay_windows, params, process_config, bread= None, flag_sets=None ):
    raise NotImplementedError(' create_mooth_baseline not defined for  $s config' % config.__class__.__name__)

@create_smoothed_baseline.register(Full)
@create_smoothed_baseline.register(Incremental)
def create_smoothed_baseline_normal(config, hist_df, geogs, geog_count, geog_windows, overlay_windows, params, process_config, bread= None, flag_sets =None ):
    ''' To be expandded to perform all steps in smoothing
    return smooth_all_geogs with the standard dataset 
    '''
    weeks = config.hist_lookback
    #Run main smoothing
    res=  smooth_all_geogs(config,
                  process_config,
                  hist_df,
                  geogs,
                  geog_count,
                  geog_windows,
                  overlay_windows,
                  params = params,
                  total_units='sales',
                  preped_units='deseasonalized_sales', 
                  result_units = 'deseasonalized_baseline',
                  bad_day_flags='flags',
                  flag_sets =flag_sets,
                  bread=bread )   
   
    return res
@create_smoothed_baseline.register(Seasonality)    
def create_smoothed_baseline_seasonality(config, hist_df, geogs, geog_count, geog_windows, overlay_windows, params, process_config, bread= None, flag_sets=None ):
    ''' Seasonality is calculated on the cleaned total sales 
    '''
    return smooth_all_geogs(config,
                  process_config,
                  hist_df,
                  geogs,
                  geog_count,
                  geog_windows,
                  overlay_windows,
                  params = params,
                  total_units='sales',
                  preped_units='sales', 
                  result_units='baseline_for_seasonality',
                  bad_day_flags='flags',
                  flag_sets =flag_sets,
                  bread=bread )   
   
@create_smoothed_baseline.register(Holiday)
def create_smoothed_baseline_holiday(config, hist_df, geogs, geog_count, geog_windows, params, process_config, bread= None, flag_sets=None ):
    ''' For Holidays we can use the existing baseline
    
    Return the input unchanged and we will have generated no exceptions
    '''
    return hist_df, pd.DataFrame()

def calc_DOW_factor (hist,alpha ):
    '''
    
    EWMA calcualtes the intemedite values replicating the shape of the input.  
    WE only need the final value.
    ''' 
    res =ewma(hist, (1- alpha)* alpha, 0, 0 ,1)
    return res[-1]

@njit
def apply_DOW_factor( baseline,  zeros, factor , applied_baseline, ):
    ''' By construction factor is seven values which are either 0 or a positive non-zero number, st all non zero values are identical '''
    
    for i in xrange(baseline.shape[0]):
        for j in xrange(baseline.shape[2]):
            applied_baseline[i,:,j]  =  zeros if factor [i,j] ==0 else applied_baseline[i,:,j]/factor[i,j]
    return applied_baseline
@singledispatch
def get_DOW_factors(process_config, hist_df,  geogs, geog_count, geog_windows, params, config, bread= None):
    ''' given a  daily history stream calculate a DOW factor'''
    raise TypeError("Object of class %r is not registered for aget_DOW_fsctor" % process_config.__class__.__name__)

@get_DOW_factors.register(Weeks)
def get_DOW_factors_null(process_config, hist_df,  geogs, geog_count, geog_windows, params, config, bread= None):
    ''' No DOW calculation on weekly time series'''
    return pd.DataFrame()

@get_DOW_factors.register(Days)
@get_DOW_factors.register(DOW)
def get_DOW_factors_implemented(process_config, hist_df,  geogs,  geog_windows, config, bread= None):
    '''This is defined for both Days and DOW configuration but should only be used if  process configuration   is DOW.
    
    If a geog has history we respect the effective window  for that geog. 
    Otherwise we are processing an adu  proxy and we open it up'''
    
    #the window to use for proxies
    NullWindow  = GeogWindow(0,0, config.hist_lookback, 6)
    publish_hist  = hist_df.loc[hist_df.index.get_level_values('bday') >= config.publish_start_date,:]
    (deseasonalized_baseline,)  = (publish_hist
                                       .pipe(dfreshape,
                                            ['deseasonalized_baseline'],
                                            as_shape(process_config,
                                                      len(geogs),
                                                      config.publish_window) ) )
    DOW_adjusted_baseline = np.empty_like(deseasonalized_baseline)
    DOW_factor = np.zeros((len(geogs), 7), 'float32')
    regular_open = geogs.loc[:, DAYNAMES].values
    
    # Count the number of weeks to pull in the start values
    week_offset = config.hist_lookback - config.publish_window
    alpha = config.DOW_alpha
    
    first_day  = config.publish_start_date.weekday()
    for idx, geog in enumerate(geogs.itertuples(index=False)):
        #Smooth history for ith store
        bread.push('Geog', str(geog.geog))
        
        #params = params.get_params(geog)
        
        #Updates smoothed_hist and new Good as a side effect.
        window  = geog_windows.get(geog.geog, NullWindow)
        for j in range(7) :
            if regular_open[idx,j]:
                # add the day of week to the breadcrumb
                #Need to rotate array based on earliest_date weekday
                bread.push('Day',DAYNAMES[(j+ first_day) % 7] )
                
                # we adjust the weeks ( if this is full). Days do not change 
                from_week = max(window.start_week -week_offset, 0) + (1 if window.start_day > j else 0)
                # extra sfe here value cannot be below 0 but 
                to_week   = max(window.end_week - week_offset -(1 if window.end_day < j else 0), 0)
                DOW_factor[idx,j] =  calc_DOW_factor(deseasonalized_baseline[idx,from_week:to_week,j],                                                        
                                                            alpha) 
            else:
                DOW_factor[idx,j] = 0
            
                
            bread.pop() 
        # Now normalize DOW_factor to apply 3to Baseline
        DOW_factor[idx,: ] = DOW_factor[idx,: ]/np.nansum(DOW_factor[idx,: ])
        
        bread.pop()
    return pd.DataFrame(DOW_factor, columns  = DAYNAMES, index = geogs.geog)

def explode_DOW_factor(process_config,   geogs, DOW_factor, weeks,   bread= None):
    res = np.array(as_shape(process_config, len(geogs), weeks), 'float32' ) 
    for i in range(res.shape[0]):
        for j in range(7):
            res[i,:,j] = DOW_factor[i,j]
    return res.reshape(-1)

if __name__ == '__main__':
    import doctest
    doctest.testmod()
   